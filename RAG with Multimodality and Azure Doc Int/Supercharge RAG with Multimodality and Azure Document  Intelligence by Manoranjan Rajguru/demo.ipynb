{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1a801ba-43c7-4273-a97b-5ea8b308b51f",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf268158-f53c-437c-b7c8-11cd456f6c4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T09:02:20.369242Z",
     "iopub.status.busy": "2024-04-16T09:02:20.368153Z",
     "iopub.status.idle": "2024-04-16T09:02:27.911285Z",
     "shell.execute_reply": "2024-04-16T09:02:27.908064Z",
     "shell.execute_reply.started": "2024-04-16T09:02:20.369242Z"
    }
   },
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SearchIndex\n",
    ")\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6452e6ec-2212-40ca-9333-4d195778cd23",
   "metadata": {},
   "source": [
    "### Loading the product images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09826610-b130-4b94-bc44-8478d1f765a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_DIR = \"embeddings\"\n",
    "\n",
    "os.makedirs(EMBEDDINGS_DIR, exist_ok=True)\n",
    "image_directory = os.path.join('images')\n",
    "embedding_directory = os.path.join('embeddings')\n",
    "output_json_file = os.path.join(embedding_directory, 'output.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c51d028-9ce5-4cb3-8537-6668765e25ce",
   "metadata": {},
   "source": [
    "### Create a data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c57ab3e-e95c-4cfc-b74b-b374afca6eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_client = SearchIndexerClient(acs_endpoint, AzureKeyCredential(acs_key))\n",
    "container = SearchIndexerDataContainer(name=container_name)\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=f\"{index_name}-blob\",\n",
    "    type=\"azureblob\",\n",
    "    connection_string=blob_connection_string,\n",
    "    container=container,\n",
    ")\n",
    "data_source = ds_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Done. Data source '{data_source.name}' has been created or updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e01d2ba-a5bc-4e0d-b621-fe9f69894ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Blob Storage\n",
    "blob_service_client = BlobServiceClient.from_connection_string(blob_connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "blobs = container_client.list_blobs()\n",
    "\n",
    "first_blob = next(blobs)\n",
    "blob_url = container_client.get_blob_client(first_blob).url\n",
    "print(f\"URL of the first blob: {blob_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96702a90-1d6a-4be0-8c9b-0db74ffbe467",
   "metadata": {},
   "source": [
    "### Create a embedding json using Cognitive Vision API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882d38fe-e167-4be1-95e7-1c6b627ca4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_json_file, 'w') as outfile:\n",
    "    for idx, image_path in enumerate(os.listdir(image_directory)):\n",
    "        if image_path:\n",
    "            try:\n",
    "                vector = image_embedding(os.path.join(image_directory, image_path))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image at index {idx}: {e}\")\n",
    "                vector = None\n",
    "            \n",
    "            filename, _ = os.path.splitext(os.path.basename(image_path))\n",
    "            result = {\n",
    "                \"id\": f'{idx}',\n",
    "                \"image_vector\": vector,\n",
    "                \"description\": filename\n",
    "            }\n",
    "\n",
    "            outfile.write(json.dumps(result))\n",
    "            outfile.write('\\n')\n",
    "            outfile.flush()\n",
    "\n",
    "print(f\"Results are saved to {output_json_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3318f4d0-33ee-4c41-a04f-456c3d7933a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = AzureKeyCredential(acs_key)\n",
    "# Create a search index \n",
    "index_client = SearchIndexClient(endpoint=acs_endpoint, credential=credential)  \n",
    "fields = [  \n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),  \n",
    "    SearchField(name=\"description\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=True),  \n",
    "    SearchField(\n",
    "        name=\"image_vector\",  \n",
    "        hidden=True,\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single), \n",
    "        searchable=True,\n",
    "        vector_search_dimensions=1024,  \n",
    "        vector_search_profile_name=\"myHnswProfile\"\n",
    "    ),  \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda418de-6383-48a5-a1b5-938cd33873da",
   "metadata": {},
   "source": [
    "### Configure the vector search configuration  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5653e6-3a7c-421b-8264-f7839d3af10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(  \n",
    "            name=\"myHnsw\"\n",
    "        )\n",
    "    ],  \n",
    "   profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "        )\n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "# Create the search index with the vector search configuration  \n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search)  \n",
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7c9854-236f-4f2b-ac47-25aaee89e950",
   "metadata": {},
   "source": [
    "### Ingest Embedding into Azure Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee96e2-c87a-4445-9af9-44d7a64aacf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "import json\n",
    "\n",
    "data = []\n",
    "with open(output_json_file, 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove leading/trailing whitespace and parse JSON\n",
    "        json_data = json.loads(line.strip())\n",
    "        data.append(json_data)\n",
    "\n",
    "search_client = SearchClient(endpoint=acs_endpoint, index_name=index_name, credential=credential)\n",
    "results = search_client.upload_documents(data)\n",
    "for result in results:\n",
    "    print(f'Indexed {result.key} with status code {result.status_code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77095e67-db3e-420e-878c-659bef6004e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T09:03:21.862626Z",
     "iopub.status.busy": "2024-04-16T09:03:21.861060Z",
     "iopub.status.idle": "2024-04-16T09:03:21.872729Z",
     "shell.execute_reply": "2024-04-16T09:03:21.870568Z",
     "shell.execute_reply.started": "2024-04-16T09:03:21.862626Z"
    }
   },
   "source": [
    "### Upload the images to blob store to use it during retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120ac7f6-b5cb-4175-90e0-a9b6e89913ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(image_directory):\n",
    "    for file in files:\n",
    "        local_file_path = os.path.join(root, file)\n",
    "        blob_name = os.path.relpath(local_file_path, image_directory)\n",
    "        with open(local_file_path, \"rb\") as data:\n",
    "            blob_client.upload_blob(data, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef646f5-da04-4985-bd28-dc8b1210421e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T08:53:37.851435Z",
     "iopub.status.busy": "2024-04-16T08:53:37.849328Z",
     "iopub.status.idle": "2024-04-16T08:53:37.863530Z",
     "shell.execute_reply": "2024-04-16T08:53:37.860531Z",
     "shell.execute_reply.started": "2024-04-16T08:53:37.851435Z"
    }
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5793f1fb-fce6-4a94-ba06-17419dc7d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.chat import (\n",
    "    BaseMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    PromptTemplate,\n",
    ")\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.runnables import Runnable, RunnablePassthrough\n",
    "from langchain_community.tools.convert_to_openai import format_tool_to_openai_function\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain.agents.output_parsers.openai_functions import (\n",
    "    OpenAIFunctionsAgentOutputParser,\n",
    ")\n",
    "from langchain.agents.format_scratchpad.openai_functions import (\n",
    "    format_to_openai_function_messages,\n",
    ")\n",
    "from langchain.memory import PostgresChatMessageHistory\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.schema.messages import AIMessageChunk\n",
    "import os\n",
    "from uuid import uuid4\n",
    "from typing import Optional\n",
    "\n",
    "from custom_tool import ImageSearchResults\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec9788-e1b0-474d-8be5-40cad4d79628",
   "metadata": {},
   "source": [
    "### Loading LangChain LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769ea850-f743-464f-ba60-5600eb00bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key=os.environ[\"AZURE_OPENAI_KEY\"],\n",
    "    api_version=\"2023-12-01-preview\",\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    model=\"gpt-4-turbo\",\n",
    ")\n",
    "prefix=\"\"\"You are rambo a helpful Fashion Agent who help people navigating and buying products online\n",
    "\n",
    "Note:\n",
    "\n",
    "\\\\ Show Prices always in INR\n",
    "\\\\ Always try user to buy from the buy now link provided\"\"\"\n",
    "suffix = \"\"\n",
    "\n",
    "tools = [ImageSearchResults(num_results=5)]\n",
    "llm_with_tools = llm.bind(\n",
    "    functions=[convert_to_openai_function(t) for t in tools]\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=prefix),\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "    AIMessage(content=suffix),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "]\n",
    "input_variables = [\"input\", \"agent_scratchpad\"]\n",
    "prompt = ChatPromptTemplate(input_variables=input_variables, messages=messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276aad25-c914-49b6-8fe2-fea99965a6a0",
   "metadata": {},
   "source": [
    "### Creating an Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097a410f-53b6-4056-bd8c-b0890747127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    RunnablePassthrough.assign(\n",
    "        agent_scratchpad=lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        )\n",
    "    )\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "message_history = PostgresChatMessageHistory(\n",
    "        connection_string=os.environ[\"POSTGRES_CONNECTION_STRING\"],\n",
    "        session_id= identifier + str(uuid4()),\n",
    "    )\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cefd0d9-e6ff-4734-b1fb-c4ba7e4e0b6c",
   "metadata": {},
   "source": [
    "### Running Agent based on input Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50fee56-c44d-4cd9-a379-366a6db9818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RunnableConfig(callbacks = [cl.AsyncLangchainCallbackHandler()])\n",
    "input = \"Blue tshirt for summer\"\n",
    "async for patch in agent_executor.astream_log({\"input\": input, \"chat_history\": message_history.messages}, \n",
    "                                              config = RunnableConfig(callbacks = [cl.AsyncLangchainCallbackHandler(stream_final_answer = True)])):\n",
    "    for op in patch.ops:\n",
    "        if op[\"op\"] != \"add\":\n",
    "            continue\n",
    "        value = op[\"value\"]\n",
    "        if not isinstance(value, AIMessageChunk):\n",
    "            continue\n",
    "        if value.content == \"\":\n",
    "            continue\n",
    "        await msg.stream_token(value.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3593b8bb-8c55-447b-9c86-eea8199f3e06",
   "metadata": {},
   "source": [
    "### From a given input image search Product Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d9c5ce-db26-4107-86af-4442b1224add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "client = AzureOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eb264f-a631-4830-b5ef-b8d5499c2d29",
   "metadata": {},
   "source": [
    "### Describe Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d3fcdc-1f3e-4e1f-8d2f-25cda5b66c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_system_prompt = '''\n",
    "    You are a system generating descriptions for furniture items, decorative items, or furnishings on an e-commerce website.\n",
    "    Provided with an image and a title, you will describe the main item that you see in the image, giving details but staying concise.\n",
    "    You can describe unambiguously what the item is and its material, color, and style if clearly identifiable.\n",
    "    If there are multiple items depicted, refer to the title to understand which item you should describe.\n",
    "    '''\n",
    "\n",
    "def describe_image(img_url, title):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4-vision-preview\",\n",
    "    temperature=0.2,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": describe_system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": img_url,\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": title\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51486a64-5b6c-43c4-a436-4d90506f314a",
   "metadata": {},
   "source": [
    "### Captioning Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd37df9-06c2-4651-a7d2-c631173c3765",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_system_prompt = '''\n",
    "Your goal is to generate short, descriptive captions for images of furniture items, decorative items, or furnishings based on an image description.\n",
    "You will be provided with a description of an item image and you will output a caption that captures the most important information about the item.\n",
    "Your generated caption should be short (1 sentence), and include the most relevant information about the item.\n",
    "The most important information could be: the type of the item, the style (if mentioned), the material if especially relevant and any distinctive features.\n",
    "'''\n",
    "\n",
    "few_shot_examples = [\n",
    "    {\n",
    "        \"description\": \"This is a multi-layer metal shoe rack featuring a free-standing design. It has a clean, white finish that gives it a modern and versatile look, suitable for various home decors. The rack includes several horizontal shelves dedicated to organizing shoes, providing ample space for multiple pairs. Above the shoe storage area, there are 8 double hooks arranged in two rows, offering additional functionality for hanging items such as hats, scarves, or bags. The overall structure is sleek and space-saving, making it an ideal choice for placement in living rooms, bathrooms, hallways, or entryways where efficient use of space is essential.\",\n",
    "        \"caption\": \"White metal free-standing shoe rack\"\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"The image shows a set of two dining chairs in black. These chairs are upholstered in a leather-like material, giving them a sleek and sophisticated appearance. The design features straight lines with a slight curve at the top of the high backrest, which adds a touch of elegance. The chairs have a simple, vertical stitching detail on the backrest, providing a subtle decorative element. The legs are also black, creating a uniform look that would complement a contemporary dining room setting. The chairs appear to be designed for comfort and style, suitable for both casual and formal dining environments.\",\n",
    "        \"caption\": \"Set of 2 modern black leather dining chairs\"\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"This is a square plant repotting mat designed for indoor gardening tasks such as transplanting and changing soil for plants. It measures 26.8 inches by 26.8 inches and is made from a waterproof material, which appears to be a durable, easy-to-clean fabric in a vibrant green color. The edges of the mat are raised with integrated corner loops, likely to keep soil and water contained during gardening activities. The mat is foldable, enhancing its portability, and can be used as a protective surface for various gardening projects, including working with succulents. It's a practical accessory for garden enthusiasts and makes for a thoughtful gift for those who enjoy indoor plant care.\",\n",
    "        \"caption\": \"Waterproof square plant repotting mat\"\n",
    "    }\n",
    "]\n",
    "\n",
    "formatted_examples = [[{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": ex['description']\n",
    "},\n",
    "{\n",
    "    \"role\": \"assistant\", \n",
    "    \"content\": ex['caption']\n",
    "}]\n",
    "    for ex in few_shot_examples\n",
    "]\n",
    "\n",
    "formatted_examples = [i for ex in formatted_examples for i in ex]\n",
    "\n",
    "def caption_image(description, model=\"gpt-4-turbo-preview\"):\n",
    "    messages = formatted_examples\n",
    "    messages.insert(0, \n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": caption_system_prompt\n",
    "        })\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": description\n",
    "        })\n",
    "    response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    temperature=0.2,\n",
    "    messages=messages\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739da6db-773d-452e-b2ec-91336d2420d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_and_caption(primary_image):\n",
    "    img_description = describe_image(primary_image)\n",
    "    caption = caption_image(img_description)\n",
    "    return {\n",
    "        'img_description': img_description,\n",
    "        'caption': caption\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1655524d-e790-4f28-9efe-79cdc25a2f45",
   "metadata": {},
   "source": [
    "### Search the Catalog Image from the above Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b82a2a-2295-4e91-9bdf-2d6939bcfff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RunnableConfig(callbacks = [cl.AsyncLangchainCallbackHandler()])\n",
    "result = tag_and_caption(\"image.png\")\n",
    "async for patch in agent_executor.astream_log({\"input\": result[\"caption\"], \"chat_history\": message_history.messages}, \n",
    "                                              config = RunnableConfig(callbacks = [cl.AsyncLangchainCallbackHandler(stream_final_answer = True)])):\n",
    "    for op in patch.ops:\n",
    "        if op[\"op\"] != \"add\":\n",
    "            continue\n",
    "        value = op[\"value\"]\n",
    "        if not isinstance(value, AIMessageChunk):\n",
    "            continue\n",
    "        if value.content == \"\":\n",
    "            continue\n",
    "        await msg.stream_token(value.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
